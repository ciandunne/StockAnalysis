{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection, Parsing, and Processing of Stock Data for Four Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib as ul\n",
    "import bs4\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocks used: Amazon, Netflix, Delta Air Lines, Ford \n",
    "\n",
    "Declaring important data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix for fetching the data\n",
    "html_prefix = \"http://mlg.ucd.ie/modules/COMP30760/stocks/data-\"\n",
    "\n",
    "# stocks for study\n",
    "stock_names = [\"Amazon\", \"Netflix\", \"Delta Air Lines\", \"Ford\"]\n",
    "\n",
    "# codes which the stock market uses to label these companies\n",
    "stock_ids = {\"Amazon\":\"AMZN\", \"Netflix\":\"NFLX\", \"Delta Air Lines\":\"DAL\", \"Ford\":\"F\"}\n",
    "\n",
    "# creating a data directory in case it doesnt already exist\n",
    "dir_data = Path(\"data\")\n",
    "dir_data.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "Function which retrieves the data from the html page of any given stock\n",
    "\n",
    "Example link to recreate: http://mlg.ucd.ie/modules/COMP30760/stocks/data-amzn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(stock_name):\n",
    "    # make sure the stock code is in lower case for the link to work\n",
    "    link = html_prefix + stock_ids[stock_name].lower() + \".html\"\n",
    "    response = ul.request.urlopen(link)\n",
    "    html = response.read().decode()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which finds the order in which the columns are stored on the html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cols(html):\n",
    "    parser = bs4.BeautifulSoup(html,\"html.parser\")\n",
    "    columnshtml = parser.find(\"thead\")\n",
    "    attributes = []\n",
    "    for match in columnshtml.find_all(\"td\"):\n",
    "        text = match.get_text()\n",
    "        text = text.strip()\n",
    "        attributes.append(text)\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts the raw data to a dataframe indexed by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_data(stock_name, html):\n",
    "    cols = find_cols(html)\n",
    "    rows = []\n",
    "    parser = bs4.BeautifulSoup(html,\"html.parser\")\n",
    "    # finds each table in the data set\n",
    "    for match in parser.find_all(\"tbody\"):\n",
    "        # finds each row in the table\n",
    "        for data_row in match.find_all(\"tr\"):\n",
    "            items = []\n",
    "            \n",
    "            # cleans the data in the row so that it is convenient to use\n",
    "            for value in data_row.find_all(\"td\"):\n",
    "                item = value.get_text()\n",
    "                item = item.strip()\n",
    "                items.append(item)\n",
    "\n",
    "            # if the first columns item does not mathc the stock code then the row is blank and it is ignored\n",
    "            if items[0] == stock_ids[stock_name]:\n",
    "                row = {}\n",
    "                \n",
    "                # get index of each of the columns relating tp the date\n",
    "                daycol = cols.index(\"Day\")\n",
    "                monthcol = cols.index(\"Month\")\n",
    "                yearcol = cols.index(\"Year\")\n",
    "                \n",
    "                #convert the month to a number no matter what way it is stored\n",
    "                if items[monthcol].isnumeric():\n",
    "                    month_holder = datetime.datetime.strptime(items[monthcol], \"%m\")\n",
    "                else:\n",
    "                    #slice so that months stored as full words also can be treated as shortened months\n",
    "                    month_holder = datetime.datetime.strptime(items[monthcol][:3], \"%b\")\n",
    "                month_num = month_holder.month\n",
    "                \n",
    "                row[\"Date\"] = datetime.datetime(int(items[cols.index(\"Year\")]), month_num, int(items[cols.index(\"Day\")]))\n",
    "\n",
    "                # close is the only necssary data to record\n",
    "                row[\"Close\"] = float(items[cols.index(\"Close\")])\n",
    "\n",
    "                rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe of each stock and recording them in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks = {}\n",
    "for stock_name in stock_names:\n",
    "    html = data_collect(stock_name)\n",
    "    df_stocks[stock_name] = parse_raw_data(stock_name, html)\n",
    "    df_stocks[stock_name] = df_stocks[stock_name].set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Verification\n",
    "\n",
    "Verify that the stats were recorded for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Close\n",
      "Date                   \n",
      "2019-10-01  1735.650024\n",
      "2019-10-02  1713.229980\n",
      "2019-10-03  1724.420044\n",
      "2019-10-04  1739.650024\n",
      "2019-10-07  1732.660034\n",
      "                 Close\n",
      "Date                  \n",
      "2019-10-01  269.579987\n",
      "2019-10-02  268.029999\n",
      "2019-10-03  268.149994\n",
      "2019-10-04  272.790009\n",
      "2019-10-07  274.459991\n",
      "                Close\n",
      "Date                 \n",
      "2019-10-01  57.009998\n",
      "2019-10-02  54.349998\n",
      "2019-10-03  52.830002\n",
      "2019-10-04  53.810001\n",
      "2019-10-07  53.360001\n",
      "            Close\n",
      "Date             \n",
      "2019-10-01   8.90\n",
      "2019-10-02   8.61\n",
      "2019-10-03   8.71\n",
      "2019-10-04   8.74\n",
      "2019-10-07   8.68\n"
     ]
    }
   ],
   "source": [
    "for stock_name in stock_names:\n",
    "    print(df_stocks[stock_name].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for any null values in the stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close    26\n",
      "dtype: int64\n",
      "Close    29\n",
      "dtype: int64\n",
      "Close    24\n",
      "dtype: int64\n",
      "Close    38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for stock_name in stock_names:\n",
    "    print(df_stocks[stock_name].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing all the null values with the previous days values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close    0\n",
      "dtype: int64\n",
      "Close    0\n",
      "dtype: int64\n",
      "Close    0\n",
      "dtype: int64\n",
      "Close    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for stock_name in stock_names:\n",
    "    if(df_stocks[stock_name].isnull().sum().sum() != 0):\n",
    "        df_stocks[stock_name] = df_stocks[stock_name].fillna(method = 'ffill')\n",
    "        \n",
    "    # if the first values in the dataframes are null it will replace them with the next value instead of the previous which doesnt exist\n",
    "    if(df_stocks[stock_name].isnull().sum().sum() != 0):\n",
    "        df_stocks[stock_name] = df_stocks[stock_name].fillna(method = 'bfill')\n",
    "        \n",
    "    print(df_stocks[stock_name].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the data to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(stock_name): \n",
    "    fname = \"%s.json\" % stock_ids[stock_name]\n",
    "    out_path = dir_data / fname\n",
    "    print(\"Writing %s\" % out_path)\n",
    "    df_stocks[stock_name].to_json(out_path, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data\\AMZN.json\n",
      "Writing data\\NFLX.json\n",
      "Writing data\\DAL.json\n",
      "Writing data\\F.json\n"
     ]
    }
   ],
   "source": [
    "for stock_name in stock_names:\n",
    "    store(stock_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
